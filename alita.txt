Hello community. How can we outperform OpenAI deep research or even outperform Manus AI? We have a brand new idea. It's called Alita. It goes down to the DNA of our AI agents. And yes, we will compare it here to a rag MCP. Interested? Then let's start this video. We start with a paradigm shift in the agent design itself. So we have a new idea to have a minimal predefin right at the start but have a maximal self evolution of our agentic system and we achieve this simply by the dynamic capability expansion via an MCP our model context protocols we just implement it in an intelligent way Alita doesn't just use your tools it autonomously creates the tools it refineses those tools, it reuses them, it stores them by generating here task related. So really absolutely narrow down MCPS from open source information like GitHub libraries and then Alita sets up automated environments and does a validation of the code. So we do have here a key mechanism of a self evolution with its dynamic MCP generation pipeline. So whenever I hear the system faces here a functional gap, Alita says, "Oh, I don't have the tools for this. I'm not clever enough. I have to find here new ways to increase my intelligent as an AI system." Simple. It searches you for relevant code on the internet, synthesizes here MCPs, configures their runtime environments, and validates their utility. encapsulated stored create here self-expanding reusable library of capabilities and we move beyond a mer tool invocation to on demand tool synthesis. How good is this? Before we have a deeper look, is it worth looking at it at all? And here we have the Gaia benchmark data and you see here for level one, level two, level three and then here the average, the total. Oh yeah. So, OpenAI deep research has this performance. Manus AI has this performance in orange. And blue is the system that we are going to talk about in this video. And if you look here at the total average, I have to say this is a nice performance jump compared to Manus AI or OpenAI deep research. How is this possible? Let's have a look. For those of you who are not really familiar with Gaia the benchmark year for general AI assistance November 2023 beautiful from fair meta hugging phase autog you find all their methodology over there. So I told you we have a new paradigm. We have a minimal predefinition. We are really light at the start. We give the if you want the robot our AI system very few basic tools and it will introduce you to all of the tools we're going to use here. Then we have agents and we start only with two agents. We have the brain if you want the manager agent and then we just need access to our knowledge source to the internet. That's it. So we have a web agent. This is all that we need. You might say but is this possible? Yeah because we will apply a maximal self evolution. We will teach you the robot how to create how to code new tools for itself whenever it needs them and only when it needs them. You don't start with 10 or 15 tools you hardly use. I don't know in 20% of the cases. It is not just about using the tool. It is designing them for a very specific query whenever you need them. So this is here the classical image that you have know a traditional here generalist agent. We have a web agent. We have a path general classifier. We have a URL text extractor agent. We have an image captioner agent. We have an agent for here the zooming in. We have other agents. We have a YouTube caption crawler agent. And we have here the central intelligence, the manager agent. And all of this we activate, we start up, we boot up. And my goodness, we have an overhead. If we have a simple task, we don't need all of this. So let's move on to a much simpler alita. So what we have, we have a web agent and we have a manager agent. And this is it. And now whatever is my query as a human user, now the system starts. And the manager agent has to have the intelligence to create tools. go to the internet, go to GitHub, create code, validate, set up an environment, and create the tools necessary to solve my task. So, MCP creation, then we put it here in a toolbox, an MCP box. I love it. And we have a self- evvolving system, minimal predefin, maximum self evolution. And I think it's a perfect time to introduce you to the original study here, Alita May 26, 2025 by Princeton University, Chinua University, Shanghai Jaong University, University of Michigan, Ten Xiao and Chrissy Jen Institute and the Chinese University of Hong Kong. Beautiful group here of brilliant study. a generalist agent enabling here a scalable agentic reasoning with a minimal predefin and a maximum self evolution. Have a look at this study. It is absolutely amazing. And you know what? I'm going to tell you a story because we are humans and humans love stories. So what is it all about? You have a task. Alita is giving me a problem like find the number mentioned in a particular YouTube video after the dinosaurs appear. So, we have a brainstorming session by Alita and the manager agent now the central intelligence thinks now hm I don't have a built-in YouTube subtitle extractor I need to create one I need to code one so it goes to the web search web agent web agent searches your online Google GitHub how to get YouTube transcript or Python library for YouTube subtitles might find here open source library yeah YouTube transcript API then it generates you a tool a script using here an LLM, GP4, omni or whatever you have or a sonnet. It writes a small piece of code, let's say a Python script and it uses the library it found to perform it a specific action. It also figures out how to set up here the coding environment for the script like how to install the YouTube transcript API. Then it will test this tool. So it runs this new script in a safe isolated space simply to say to see if it works. And if it works and if it provides here exactly what it wants, it says, "Hey, great. So now I saved the tool as an MCP." So Alita wraps up it neatly and saves it in its MCP box. So this new YouTube subtitle crawler MCP now if you like call it this is now our new tool and we can use it whenever we want it without rebuilding it. And it solves the task. It uses the newly created MCP to get the subtitles, find the dinosaur scene, and extract the number. So, you see, it's kind of a self-learning system. No human intervention at all necessary. No software developer, nothing. The beauty is that it isn't limited to a predefined set of tools. No, like in MCPR rack, it can adapt to new task by creating here specific tools that it needs even from a multitude of GitHub repos. If you have the LLM, the core of your uh manager agent, if it's intelligent enough to distill it the necessary pieces together, it just creates the tool that it needs. And this is done in real time. And as it encounters more diverse problem, it evolves here a richer set of capabilities with the help of more complex solving tools. So you see it's a relative simple idea, but the complexity is simply shifted to the ability to generate complexity as new tools that can solve the complexity as required. Beautiful. No monolytic agent with thousand of built-in functions. So no problem to handle task it has never seen before out of distribution not a problem at all. Whatever if there's some piece of information it can find online it can write the necessary code for itself. What is also amazing the distillation functionality if the MCPL just creates can be shared now with other much less powerful agent. So if you have a little I don't know mini or you have here a deepse R1 distilled or whatever to a three billion free trainable parameter model you still have access to MCPs alters created here for the specific task. So if you want the intelligence to solve a particular query is now outsourced to our MCPS our tools that we use the little LLM just need to understand hey this is the problem I have here a tool for this particular problem I bring them together and this is it an agent with a weaker LLM can benefit from the MCPS generated by an agent with a stronger reasoning LLM Beautiful. So here you have it. This is it. So we have here a human question. This is great. Our manager agent here in the minimal configuration. Yeah, if it's really the minimal configuration, the MCP is relatively empty. So you have if you really start from zero, you have a little bit of a warm-up phase. But hey, if you have two, three task, you will see you will fill up your MCB box real fast. manager agent analyzers did MCP creation. Yeah, let's come now to the tools. Let's have a look. So, we will have a MCP brainstorming tool. We will have an open source open-source searching functionality, a script generation, a virtual environment execution here of the code. We will encapsulate it in a put it in MCP box and have a self- evvolving system. Simple, beautiful. So, let's start. I just wanted to show you you don't have to find this paper. This is here the rack MCP paper. I love this paper and yeah from May 6, 2025 and they say our rack MCP enhances the efficiency and accuracy of agent. Now it is not the classical rack system that I showed you in one of my last videos but now we're retrieving the most relevant tools from a large collection of tools from a database of tools only. So we moved away from textbased databases or numerical databases. Now we go here to a higher complexity level of objects that we have now. The tools we have a rag MCP. Great. Yeah, Alita itself I'm a little bit early as you see it was just updated 2 hours ago. They are loading now in the figures. So whenever you come here to the GitHub repo you should have the code. You should have much more bone meat to the bone here. But for me yes I can see that they're uploading currently. So please have a look yourself whenever you see this video. There should be much more information for you available. You know this sentence, hey don't just give AI tools. Teach a human how to make a boat. I mean how to teach an AI how to make tools. No. So we shift here from a static capability of an AI system to a dynamic self-improving system where we have an on the-fly programming of the necessary agents itself. Agent create agents. Agent can clone other agents. This is kind of if you want the DNA here of the agent replication itself to build specialized agents. Agent creator agents. Who needs human? Alita is about building here any agent that learns and grows by figuring out how to build its own solutions. Such a beautiful idea. We dash off into the fractile dimension. But let's stick here with the particular publication because I wanted to show you the basic set of tools that we have here. So you remember minimal predefin maximal self evolution. We have a manager agent the brain and the brain needs a little bit of something. It needs some basic tools and the web agent has also access to the internet. Let's have a look at the tools. First our brain the manager agent. This is the central coordinate. This is really all about we need here one primary agent within the framework of Alita. So we have here when given here a prompt manager calls here an MCP brainstorming tool to determine whether additional tools are needed. If we have already something in our MCP toolbox and which specific tools are required at all. If the manager sees the task is too complex, it start to decompose the task like any other LLM into particular lower linear complexity subtask dispatches them maybe to the web agent to find solution on GitHub or wherever you are familiar with this copilot and generates then the required external tools in builds up the environment tests it validates it great utilizes the information from the web agent to retrieve these new tools the environment configuration instruction and beautiful so let's have a look the MCP brainstorming since LLMs often exhibit some overconfidence you know they think yeah I can do this and they decided here the team to introduce MCB brainstorming to conduct a preliminary capability assessment by providing both the task and a description and specialized prom facilitate self assessment of the capabilities Beautiful. We have a script generation tool. This is simply the code building utility. GitHub links. It builds everything and the script generation tool generates now the environment script to create here the required environment for the code running. And you know it lex tool code running tool executed within an isolated environment. If everything is great, if you get a green light says beautiful, this are the expected result. The tool is registered in a system and there's a reusable MCP tool. This is it. Summary brainstorming script generation code running as easy as can be. I think what's really nice is this selfinforcing self reinforcing cycle. And Alita has here really the power to autonomously expand its capabilities. Maybe from time to time a human should have it. Look what's happening. But otherwise it will be its MCP tools in a beautiful way. The web agent couldn't be easier. Guess what? Retrieves the rele information for the external sources. Retrieval of domain specific code. You can imagine this beautifully. We have a simple text browser. Go with whatever you want. We have some control tools, the visit tool, the page up tool, the page down tool. Then you're not going to believe it. We have the Google search tool or the GitHub search tool. And yeah, you can imagine exactly what happened. Now to the detailed benchmark data they have tested two they have tested Alita on the GIA on multiple levels and the total and on other tests here and they went with a classical claw 3.7 set and the GPD4 they said okay there's a new set for I love it with the include here the latest model to give you here a benchmark and if you look here at the benchmark you see that with clawsonet 4 the performance of the system in anet three breaks It's down from 96 it crashes down to 88 and they say they they tested everything. They did it multiple times. They don't understand why suddenly with a sonet 4 the performance here drops from 96 which is beautiful performance no of a clock 3.7 and with the sonet 4 it's yeah it crashes down but in total they can keep it from 86 to 87%. So we are yes beautiful but they say they continued with clo 3.7 maybe we should learn from them in general they say but careful if you go with a less intelligent agent where an LLM is not as powerful in coding and they say let's say we just go with a four mini system you see now if you do the same Alita system on each level we have much less performance so the coding performance of our LLM. And if you go with a mini or a 3 billion or a 4 billion model, this is not recommended. You need a strong performance in coding because the LLM the agent here is coding here a lot of so you see with the classical 3.72% and here with a GBD4 omni mini only 43%. So this is important plus you have to get take care about the complexity of the MCP generation while the concept is self-evolution the actual process of searching scripting and environment managing here for complex novel tool is still really errorprone and computationally intensive. So please choose the right LLM for some real heavy task. I know it is a challenge. You would like to go with cheaper much much smaller models but as you can see here in the performance data they are hardly worth it. I like this to end this video with the conclusion from the authors. This is a screenshot from their conclusion. And they say, "Hey, we introduce here Alita a generalist agent designed with the principle of minimal predefinolution. And by significantly reducing here the reliance on manually predefined tools and manual defined workflows for the direct solving, Alita leverages here a creative autonomous capability in real time, facilitating scalable agentic reasoning. It's a beautiful idea. We have seen it before, but if I get my hands on this code, I love to try it out. It demonstrates simplicity in design, does not undermine, but rather enhances the performance and the adaptability of generalist agent. So nice. Next up in the evolution of our agents. So there you have it. I hope you enjoyed it. Alita really going down to the DNA of agents. Agent creator agents. And as I showed you here, if you go here with a very lightweight structure here right at the beginning, you don't have to carry in your startup conferation with multiple agents. You start very light and you just build up what you absolutely need. What an elegant solution. What a simplicity here in the startup configuration. If you like to see more videos like this, hey, why not subscribe and I see you in the next one.